---
title: "UQR 2"
output: html_document
date: "2026-01-25"
---

```{r}

# --- CODE DE PRÉPARATION DES DONNÉES POUR RENDRE LE SCRIPT INDÉPENDANT ---

# Charger les packages nécessaires
library(haven)
library(dplyr)
library(stringr)
library(purrr)
library(forcats)

# Charger les données directement depuis le fichier DTA
data <- read_dta("eu-lfs 2023 sample.dta")

# Créer data_modifiable (équivalent au premier script)
data_modifiable <- data

# Transformer les variables en facteurs et gérer les "Not available"
factor_vars <- c("refmonth", "hhtype", "ageresid", "hhlink", "wkstat", "absreas", 
                 "empstat", "numjob", "seekwork", "wantwork", "actmetne", "wishmore",
                 "avaireas", "ilostat", "homework", "stapro", "isco08_3d", "eseg_2d",
                 "ftpt", "temp", "tempdur", "tempreas", "tempagcy", "ftptreas",
                 "varitime", "lookoj", "hwwish", "needcare")

for (var in factor_vars) {
  if (var %in% names(data_modifiable)) {
    data_modifiable <- data_modifiable %>%
      mutate(!!sym(var) := as_factor(!!sym(var)),
             !!sym(var) := na_if(!!sym(var), "Not available"))
  }
}

# Transformer la variable sexe (1=homme, 2=femme) en indicatrice (1=femme, 0=homme)
if ("sex" %in% names(data_modifiable)) {
  data_modifiable <- data_modifiable %>%
    mutate(
      sex = case_when(
        sex == 1 ~ 0,    # Homme
        sex == 2 ~ 1,    # Femme
        TRUE ~ NA_real_
      )
    )
}

# Renommer les colonnes avec leurs labels (comme dans le premier script)
labels <- sapply(data_modifiable, function(x) attr(x, "label"))
labels[sapply(labels, is.null) | labels == ""] <- names(data_modifiable)[sapply(labels, is.null) | labels == ""]
names(data_modifiable) <- labels

# Rendre les noms uniques au cas où
names(data_modifiable) <- make.unique(names(data_modifiable), sep = ".")

# Vérification rapide
cat("Dimensions de data_modifiable:", dim(data_modifiable), "\n")
cat("Variables clés disponibles:\n")
cat("  - Being in employment:", "Being in employment" %in% names(data_modifiable), "\n")
cat("  - Number of hours usually worked, main job:", "Number of hours usually worked, main job" %in% names(data_modifiable), "\n")
cat("  - Yearly weighting factor:", "Yearly weighting factor" %in% names(data_modifiable), "\n")
cat("  - Age in completed years:", "Age in completed years" %in% names(data_modifiable), "\n")
cat("  - Year of survey:", "Year of survey" %in% names(data_modifiable), "\n")
cat("  - Country of residence:", "Country of residence" %in% names(data_modifiable), "\n")
cat("  - Highest level of education (ISCED-11, 3 levels):", "Highest level of education (ISCED-11, 3 levels)" %in% names(data_modifiable), "\n")
cat("  - Economic activity, main job, 2008 onwards (NACE Rev 2, 1 digit):", "Economic activity, main job, 2008 onwards (NACE Rev 2, 1 digit)" %in% names(data_modifiable), "\n")
cat("  - Permanency of main job:", "Permanency of main job" %in% names(data_modifiable), "\n")
cat("  - Full- or part-time, main job (self-defined):", "Full- or part-time, main job (self-defined)" %in% names(data_modifiable), "\n")

# Vérifier comment est codée la variable "Being in employment"
cat("\nCodage de 'Being in employment':\n")
if ("Being in employment" %in% names(data_modifiable)) {
  print(table(data_modifiable$`Being in employment`, useNA = "always"))
}

# --- FIN DU CODE DE PRÉPARATION ---


```

----- Préparation des variables clés expliquant les quantiles des heures de travail habituellement travaillées: ------------

Y : heures de travail habituellement travaillées


Variables de base (toujours inclure) :

- female : sexe (effet genre documenté)
- age et age² : relation non-linéaire avec les heures
- education : niveau d'éducation (catégoriel, 3 niveaux ISCED)

Variables structurelles (essentielles pour la polarisation) :

- sector : secteur économique (NACE 1 digit) → effet de composition
- contract_type : contrat temporaire/permanent → précarité
- full_part : temps plein/partiel → segmentation du marché

Variables de contrôle (optionnelles mais recommandées) :

country : effets fixes pays (hétérogénéité institutionnelle)
year : tendance temporelle ou effets fixes année

Variables d'intérêt spécifiques (selon vos hypothèses) :

- Interactions : female × education, female × sector

- Variables familiales (si disponibles) : présence d'enfants, statut marital

```{r}
# 
# 
analysis_data <- data_modifiable %>%
  mutate(
    hours = `Number of hours usually worked, main job`,
    weight = `Yearly weighting factor`,
    female = sex,
    age = `Age in completed years`,
    year = `Year of survey`,
    country = `Country of residence`,
    education = `Highest level of education (ISCED-11, 3 levels)`,
    sector = `Economic activity, main job, 2008 onwards (NACE Rev 2, 1 digit)`,
    contract_type = case_when(
      `Permanency of main job` == "Permanent job" ~ "permanent",
      `Permanency of main job` == "Fixed-term job" ~ "temporary",
      TRUE ~ NA_character_
    ),
    full_part = `Full- or part-time, main job (self-defined)`
  ) %>%
  # CORRECTION ICI : Utiliser "Employed" au lieu de 1
  filter(`Being in employment` == "Employed") %>%
  filter(!is.na(hours), hours > 0, hours < 100) %>%
  mutate(
    education = as.factor(education),
    sector = as.factor(sector),
    contract_type = as.factor(contract_type),
    full_part = as.factor(full_part)
  )

# Vérification
cat("Dimensions:", dim(analysis_data), "\n")
cat("Nombre d'années:", length(unique(analysis_data$year)), "\n")
cat("Valeurs uniques de 'year':", sort(unique(analysis_data$year)), "\n")
cat("Nombre d'observations:", nrow(analysis_data), "\n")
```





-------------- Nouveaux rif corrigés de valeurs aberrantes qui faussent les regressions --------------

```{r}

# Installation et chargement des packages nécessaires
install.packages("dineq")
install.packages("fixest")
install.packages("tidyverse")

library(dineq)
library(fixest)
library(tidyverse)

# Fonction améliorée avec gestion d'erreur et bande passante fixe
calculate_rif_robust <- function(x, tau = 0.5, bw = 1.5, min_density = 0.01) {
  # Calcul du quantile
  q <- quantile(x, probs = tau, na.rm = TRUE, type = 7)
  
  # Nombre d'observations
  n <- length(x)
  
  # Si trop peu d'observations, utiliser une densité fixe
  if (n < 50) {
    # Densité fixe basée sur l'écart interquartile
    iqr <- IQR(x, na.rm = TRUE)
    f_q <- 1 / (1.349 * iqr / (n^(1/3)))  # Règle de Silverman simplifiée
    f_q <- pmax(f_q, min_density)
  } else {
    tryCatch({
      # Estimation de densité avec bande passante fixe
      dens <- density(x, bw = bw, na.rm = TRUE, kernel = "gaussian")
      # Interpolation
      f_q <- approx(dens$x, dens$y, xout = q)$y
      f_q <- pmax(f_q, min_density)
    }, error = function(e) {
      # En cas d'erreur, utiliser une densité par défaut
      iqr <- IQR(x, na.rm = TRUE)
      f_q <- 1 / (1.349 * iqr / (n^(1/3)))
      f_q <- pmax(f_q, min_density)
    })
  }
  
  # Calcul de la RIF
  rif <- q + (tau - (x <= q)) / f_q
  return(rif)
}

# Solution plus simple : utiliser une bande passante fixe standardisée
calculate_rif_simple <- function(x, tau = 0.5, min_density = 0.02) {
  q <- quantile(x, probs = tau, na.rm = TRUE, type = 7)
  n <- length(x)
  
  # Règle de Silverman simplifiée pour la bande passante
  h <- 1.06 * sd(x, na.rm = TRUE) * n^(-1/5)
  h <- max(h, 0.5)  # Minimum de 0.5
  
  # Densité normale approximative au quantile
  f_q <- dnorm(q, mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE))
  f_q <- pmax(f_q, min_density)
  
  # Calcul RIF
  rif <- q + (tau - (x <= q)) / f_q
  return(rif)
}

# Calcul avec la méthode simple
analysis_data_corrected <- analysis_data %>%
  group_by(year, country) %>%
  mutate(
    rif_d10_new = calculate_rif_simple(hours, tau = 0.1, min_density = 0.02),
    rif_d90_new = calculate_rif_simple(hours, tau = 0.9, min_density = 0.02),
    rif_gap_new = rif_d90_new - rif_d10_new
  ) %>%
  ungroup()

# Vérification
cat("\n=== VÉRIFICATION RAPIDE ===\n")
cat("Moyenne rif_gap_new:", mean(analysis_data_corrected$rif_gap_new, na.rm = TRUE), "\n")
cat("Comparaison avec écart réel (28.75h):", 
    round(mean(analysis_data_corrected$rif_gap_new, na.rm = TRUE), 2), "h\n")

# Vérifier s'il y a des valeurs aberrantes
summary(analysis_data_corrected$rif_gap_new)
```






--------------------- Meilleur algorithme de caclul des RIF -----------------

```{r}
# Fonction RIF robuste adaptée aux heures de travail
calculate_rif_robust_adaptive <- function(x, tau = 0.5, min_density = 0.005) {
  # 1. Calcul du quantile
  q <- quantile(x, probs = tau, na.rm = TRUE, type = 7)
  n <- length(x)
  
  # 2. Estimation de densité robuste avec gestion d'erreur
  f_q <- tryCatch({
    # Estimation par noyau avec bande passante adaptative
    bw <- bw.SJ(x, na.rm = TRUE)  # Méthode Sheather-Jones robuste
    dens <- density(x, bw = bw, na.rm = TRUE, kernel = "gaussian", n = 512, 
                    from = min(x, na.rm = TRUE), to = max(x, na.rm = TRUE))
    approx(dens$x, dens$y, xout = q)$y
  }, error = function(e) {
    # En cas d'erreur, estimation par règle de Silverman simplifiée
    iqr <- IQR(x, na.rm = TRUE)
    sd_val <- sd(x, na.rm = TRUE)
    h <- 0.9 * min(sd_val, iqr/1.349) * n^(-0.2)
    1 / (2.5 * h * sqrt(2*pi))  # Approximation de densité gaussienne
  })
  
  # 3. Assurer une densité minimale
  if (is.na(f_q) || f_q < min_density) {
    # Règle de secours basée sur l'écart interquartile
    iqr <- IQR(x, na.rm = TRUE)
    if (iqr > 0) {
      f_q <- 1 / (1.349 * iqr / (n^(1/3)))
    } else {
      f_q <- 1 / (4 * sd(x, na.rm = TRUE) / (n^(1/3)))
    }
    f_q <- pmax(f_q, min_density)
  }
  
  # 4. Calcul du RIF
  rif <- q + (tau - (x <= q)) / f_q
  
  # 5. Contrôle des valeurs aberrantes (clipping soft)
  # Limiter les RIF à ±3 écarts-types du quantile
  sd_rif <- sd(rif, na.rm = TRUE)
  mean_rif <- mean(rif, na.rm = TRUE)
  if (!is.na(sd_rif) && sd_rif > 0) {
    rif <- pmax(pmin(rif, mean_rif + 3*sd_rif), mean_rif - 3*sd_rif)
  }
  
  return(rif)
}

# Application aux données
analysis_data_corrected <- analysis_data %>%
  group_by(year, country) %>%
  mutate(
    rif_d10_new = calculate_rif_robust_adaptive(hours, tau = 0.1, min_density = 0.005),
    rif_d90_new = calculate_rif_robust_adaptive(hours, tau = 0.9, min_density = 0.005),
    rif_gap_new = rif_d90_new - rif_d10_new,
    education_num = as.numeric(education),  # Ajoutez ici
    age_sq = age^2  # Ajoutez ici
  ) %>%
  ungroup()

# Vérification des résultats
cat("\n=== VÉRIFICATION DES RIFS CORRIGÉS ===\n")
cat("Moyenne rif_d10:", mean(analysis_data_corrected$rif_d10_new, na.rm = TRUE), "\n")
cat("Moyenne rif_d90:", mean(analysis_data_corrected$rif_d90_new, na.rm = TRUE), "\n")
cat("Moyenne rif_gap:", mean(analysis_data_corrected$rif_gap_new, na.rm = TRUE), "\n")
cat("Comparaison avec quantiles réels:\n")
cat("  Q10 réel:", quantile(analysis_data$hours, 0.1, na.rm = TRUE), "\n")
cat("  Q90 réel:", quantile(analysis_data$hours, 0.9, na.rm = TRUE), "\n")
cat("  Écart réel:", quantile(analysis_data$hours, 0.9, na.rm = TRUE) - 
      quantile(analysis_data$hours, 0.1, na.rm = TRUE), "\n")
```

Précision :

La polarisation des heures de travail varie selon les pays (différences institutionnelles, culturelles, économiques). En calculant les RIF par année ET pays, nous capturons :

Les différences de distribution entre pays

L'évolution temporelle spécifique à chaque pays

L'effet réel des variables individuelles sur l'écart inter-décile national

Maintenant que les RIF sont correctement calculés, vous pouvez procéder aux régressions.





----------- Vérifications préalables --------------

Nous devons d'abord vérifier que les variables sont bien formatées. Les valeurs de RIF semblent extrêmes (négatives et positives très grandes). Cela pourrait être dû à des problèmes dans le calcul des RIF ou dans les données. Cependant, procédons étape par étape.

Tout d'abord, vérifions la distribution des heures et les "mass points". Ensuite, nous ajusterons les modèles.

Note: Les RIF calculés semblent avoir des valeurs très grandes (par exemple 1318) et négatives (-64.2). Cela pourrait indiquer un problème avec la fonction de densité estimée. Mais continuons.

```{r}
# 5. Vérifications préalables essentielles

# 1. Vérifier la distribution des heures
cat("Quantiles 10% et 90% des heures :\n")
print(quantile(analysis_data$hours, probs = c(0.1, 0.9), na.rm = TRUE))

# Histogramme des heures habituellement travaillées
hist(analysis_data$hours, breaks = 50, main = "Distribution des heures travaillées", xlab = "Heures hebdomadaires")

# 2. Vérifier les "mass points" (pics à 35h, 40h)
cat("\nMass points autour de 35h-40h :\n")
mass_points <- analysis_data %>%
  filter(hours >= 30 & hours <= 45) %>%
  count(hours) %>%
  arrange(desc(n)) %>%
  head(10)
print(mass_points)

# 3. Vérifier la taille des échantillons par groupe
cat("\nTaille des échantillons par année et secteur (top 20) :\n")
sample_sizes <- analysis_data %>%
  group_by(year, sector) %>%
  summarise(n = n(), .groups = "drop") %>%
  arrange(year, sector) %>%
  head(20)
print(sample_sizes)

# Vérifier aussi les valeurs manquantes dans les variables explicatives
cat("\nValeurs manquantes par variable :\n")
missing_summary <- analysis_data %>%
  summarise(across(c(female, age, education, sector, contract_type, full_part), 
                   ~sum(is.na(.)))) %>%
  gather(variable, missing_count)
print(missing_summary)
```



--------------- Nouvelles regressions avec les nouveaux RIFs corrigés ------------

```{r}

# Ajouter l'age quadratique (effet non linéaire) et créer education_num pour les interactions


# 1. Modèles principaux avec RIF corrigés
model_basic_corr <- feols(rif_gap_new ~ female + age + age_sq + education + 
                            sector + contract_type + full_part,
                          data = analysis_data_corrected,
                          weights = ~weight,
                          vcov = "hetero")

model_country_fe_corr <- feols(rif_gap_new ~ female + age + age_sq + education + 
                                 sector + contract_type + full_part | country,
                               data = analysis_data_corrected,
                               weights = ~weight,
                               vcov = "hetero")

# Centrage de year
analysis_data_corrected <- analysis_data_corrected %>%
  mutate(year_centered = year - 2000)  # Ou year - mean(year)


model_trend_corr <- feols(rif_gap_new ~ female*year_centered + age + age_sq + education + 
                                     sector + contract_type + full_part | country,
                                   data = analysis_data_corrected,
                                   weights = ~weight,
                                   vcov = "hetero")

# 2. Modèles par décile avec RIF corrigés
model_d10_corr <- feols(rif_d10_new ~ female + age + age_sq + education + 
                          sector + contract_type + full_part | country,
                        data = analysis_data_corrected,
                        weights = ~weight,
                        vcov = "hetero")

model_d90_corr <- feols(rif_d90_new ~ female + age + age_sq + education + 
                          sector + contract_type + full_part | country,
                        data = analysis_data_corrected,
                        weights = ~weight,
                        vcov = "hetero")

# 3. Afficher les résultats
cat("\n=== MODÈLES AVEC RIF CORRIGÉS ===\n")
cat("\nModèle de base (corrigé):\n")
print(summary(model_basic_corr))

cat("\nModèle avec effets fixes pays (corrigé):\n")
print(summary(model_country_fe_corr))

cat("\nModèle avec tendance temporelle (corrigé):\n")
print(summary(model_trend_corr))
```



------------------Tableaux synthétiques ---------------


1 - Tableau comparatif des coefficients clés : Un tableau unique présentant les coefficients des variables principales (sexe, âge, éducation, type de contrat, statut d'emploi) pour les modèles 1, 2 et 3, avec leurs erreurs standard et niveaux de significativité. Cette présentation permet d'observer l'évolution des effets marginaux lorsque l'on introduit les effets fixes pays et la tendance temporelle.

2 - Tableau de décomposition par décile : Un tableau juxtaposant les coefficients des modèles 4a (D10) et 4b (D90) pour les mêmes variables principales, avec une colonne supplémentaire indiquant la différence entre les deux effets. Ce tableau révèle les asymétries dans les déterminants des extrémités de la distribution.

3 - Tableau des statistiques de qualité d'ajustement : Un tableau récapitulatif présentant pour chaque modèle le nombre d'observations, le R² ajusté, le RMSE et la Within R² le cas échéant. Cela permet d'évaluer la performance relative des spécifications.


[Corrigé] tableaux sortie console :
```{r}
# Nouvelle liste des modèles corrigés
model_list_corr <- list(
  "Modèle 1 corrigé" = model_basic_corr,
  "Modèle 2 corrigé" = model_country_fe_corr,
  "Modèle 3 corrigé" = model_trend_corr
)


# 3. Définir les coefficients à afficher (variables clés)
variables_clés <- c(
  "female" = "Femme (réf: Homme)",
  "age" = "Âge",
  "age_sq" = "Âge²",
  "education-1" = "Éducation: Non disponible",
  "education1" = "Éducation: Faible",
  "education2" = "Éducation: Moyenne",
  "education3" = "Éducation: Élevée",
  "contract_typetemporary" = "Contrat temporaire (réf: Permanent)",
  "full_partNot stated" = "Statut emploi: Non spécifié",
  "full_partFull-time job" = "Statut emploi: Temps plein (réf: Temps partiel)",
  "year" = "Tendance temporelle",
  "female:year" = "Interaction Femme × Année"
)

# Tableau comparatif des modèles corrigés
tableau_corrige <- modelsummary(
  model_list_corr,
  output = "data.frame",
  coef_map = variables_clés,  # Utilisez le même coef_map que précédemment
  gof_map = c("nobs", "r.squared"),
  stars = c('*' = 0.1, '**' = 0.05, '***' = 0.01),
  fmt = 2,
  statistic = "({std.error})"
)

cat("\n=== TABLEAU COMPARATIF CORRIGÉ ===\n")
print(tableau_corrige)
```









----------------- Tableau pour les régressions 4a et 4b ---------------

```{r}
# Estimation des modèles D10 et D90 avec RIF corrigés et effets fixes pays
model_d10_corr <- feols(rif_d10_new ~ female + age + age_sq + education + 
                           sector + contract_type + full_part | country,
                         data = analysis_data_corrected,
                         weights = ~weight,
                         vcov = "hetero")

model_d90_corr <- feols(rif_d90_new ~ female + age + age_sq + education + 
                           sector + contract_type + full_part | country,
                         data = analysis_data_corrected,
                         weights = ~weight,
                         vcov = "hetero")

# Extraction des coefficients et erreurs standard
coef_d10 <- coef(model_d10_corr)
se_d10 <- se(model_d10_corr)
coef_d90 <- coef(model_d90_corr)
se_d90 <- se(model_d90_corr)

# Variables communes
common_vars <- intersect(names(coef_d10), names(coef_d90))

# Création du tableau comparatif
tableau_decomposition <- data.frame(
  Variable = common_vars,
  Coef_D10 = round(coef_d10[common_vars], 3),
  SE_D10 = round(se_d10[common_vars], 3),
  Coef_D90 = round(coef_d90[common_vars], 3),
  SE_D90 = round(se_d90[common_vars], 3),
  Difference = round(coef_d90[common_vars] - coef_d10[common_vars], 3)
)

# Ajout des étoiles de significativité (basées sur p-value < 0.05)
pvalue_d10 <- pvalue(model_d10_corr)[common_vars]
pvalue_d90 <- pvalue(model_d90_corr)[common_vars]

tableau_decomposition$Signif_D10 <- ifelse(pvalue_d10 < 0.001, "***",
                                           ifelse(pvalue_d10 < 0.01, "**",
                                                  ifelse(pvalue_d10 < 0.05, "*", "")))

tableau_decomposition$Signif_D90 <- ifelse(pvalue_d90 < 0.001, "***",
                                           ifelse(pvalue_d90 < 0.01, "**",
                                                  ifelse(pvalue_d90 < 0.05, "*", "")))

# Réorganiser les colonnes
tableau_decomposition <- tableau_decomposition %>%
  mutate(
    D10 = paste0(Coef_D10, Signif_D10, " (", SE_D10, ")"),
    D90 = paste0(Coef_D90, Signif_D90, " (", SE_D90, ")")
  ) %>%
  select(Variable, D10, D90, Difference)

# Affichage du tableau
cat("=== TABLEAU DE DÉCOMPOSITION PAR DÉCILE ===\n")
cat("Modèle D10 (10ème centile) et D90 (90ème centile) avec effets fixes pays\n")
cat("Coefficients avec erreurs standard entre parenthèses\n")
cat("*** p<0.001, ** p<0.01, * p<0.05\n\n")

print(tableau_decomposition, row.names = FALSE)

# Calcul de la significativité de la différence
# Test d'égalité des coefficients entre D10 et D90
cat("\n=== TESTS D'ÉGALITÉ DES COEFFICIENTS (D90 - D10) ===\n")

# Pour chaque variable, tester si la différence est significative
# Nous utiliserons un test de Wald approximé
for (var in common_vars) {
  coef_diff <- coef_d90[var] - coef_d10[var]
  se_diff <- sqrt(se_d10[var]^2 + se_d90[var]^2)
  t_stat <- coef_diff / se_diff
  p_val <- 2 * pt(-abs(t_stat), df = model_d10_corr$nobs - length(coef_d10))
  
  if (p_val < 0.05) {
    cat(sprintf("%s: Différence significative (diff=%.3f, t=%.3f, p=%.4f)\n", 
                var, coef_diff, t_stat, p_val))
  }
}
```

------------------- Tableau des qualités d'ajustement etc --------------


```{r}

# Code pour extraire les statistiques de qualité d'ajustement des modèles fixest
cat("\n=== TABLEAU DES STATISTIQUES DE QUALITÉ D'AJUSTEMENT ===\n")
cat("Statistiques de qualité d'ajustement des modèles UQR\n\n")

# Fonction simple pour extraire R² ajusté d'un modèle fixest
get_adj_r2_fixest <- function(model) {
  # Méthode 1: via fitstat (préférée pour fixest)
  if (requireNamespace("fixest", quietly = TRUE)) {
    r2 <- tryCatch({
      fixest::fitstat(model, "ar2", simplify = TRUE)
    }, error = function(e) NA_real_)
    if (!is.na(r2)) return(r2)
  }
  
  # Méthode 2: via summary
  r2 <- tryCatch({
    summary(model)$adj.r.squared
  }, error = function(e) NA_real_)
  
  return(r2)
}

# Créer le tableau directement
cat(sprintf("%-25s %10s %12s %12s %12s\n", 
            "Modèle", "N", "R² ajusté", "RMSE", "Within R²"))
cat(rep("-", 71), "\n", sep = "")

# Liste des modèles et de leurs noms
model_info <- list(
  list(name = "Modèle 1 (Basique)", model = model_basic_corr),
  list(name = "Modèle 2 (Pays FE)", model = model_country_fe_corr),
  list(name = "Modèle 3 (Tendance)", model = model_trend_corr),
  list(name = "Modèle 4a (D10)", model = model_d10_corr),
  list(name = "Modèle 4b (D90)", model = model_d90_corr)
)

# Afficher les statistiques pour chaque modèle
for (info in model_info) {
  model <- info$model
  model_name <- info$name
  
  # Nombre d'observations
  n_obs <- nobs(model)
  
  # R² ajusté
  adj_r2 <- get_adj_r2_fixest(model)
  
  # RMSE - calcul direct si nécessaire
  rmse_val <- tryCatch({
    # Essayer d'obtenir le RMSE du summary
    smry <- summary(model)
    if (!is.null(smry$sigma)) {
      smry$sigma
    } else {
      # Calcul manuel du RMSE
      sqrt(sum(resid(model)^2) / (n_obs - length(coef(model))))
    }
  }, error = function(e) {
    sqrt(sum(resid(model)^2) / (n_obs - length(coef(model))))
  })
  
  # Within R² pour les modèles avec effets fixes
  within_r2 <- tryCatch({
    smry <- summary(model)
    smry$r2within
  }, error = function(e) NA_real_)
  
  # Formater l'affichage
  adj_r2_display <- ifelse(is.na(adj_r2) || is.null(adj_r2), 
                          "0.0000", sprintf("%.4f", adj_r2))
  rmse_display <- sprintf("%.3f", rmse_val)
  within_r2_display <- ifelse(is.na(within_r2) || is.null(within_r2), 
                             "0.0000", sprintf("%.4f", within_r2))
  
  # Afficher la ligne
  cat(sprintf("%-25s %10d %12s %12s %12s\n",
              model_name, n_obs, adj_r2_display, rmse_display, within_r2_display))
}

cat("\nNote: Les modèles D10 et D90 utilisent la régression RIF pour les quantiles 10% et 90%.\n")
cat("Within R² n'est disponible que pour les modèles avec effets fixes pays.\n")
```

